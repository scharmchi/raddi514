{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSY2w0CWpERa6JDXi/wAQYmbc5iZ7zQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f93581f2d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = scipy.io.loadmat('labels.mat')\n",
    "features = scipy.io.loadmat('features.mat')\n",
    "hip_images = scipy.io.loadmat('hip_images.mat')\n",
    "\n",
    "# just need the array from the dictionary\n",
    "hip_images = hip_images['hip_images']\n",
    "features = features['features']\n",
    "labels = labels['labels']\n",
    "\n",
    "# roll array so first axis represent number of instances\n",
    "hip_images = np.rollaxis(hip_images, 2)\n",
    "\n",
    "# convert string features to usable inputs for NN\n",
    "features = [list(example) for example in features]\n",
    "features = np.asarray(features).astype(np.int)\n",
    "\n",
    "labels = np.array(labels).astype(np.int)\n",
    "\n",
    "plt.hist(labels)\n",
    "# labels start at 1, make them start at 0 then one-hot\n",
    "labels = labels - 1\n",
    "y_one_hot = np.zeros((labels.size, labels.max()+1))\n",
    "y_one_hot[np.arange(labels.size), labels] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Neural Net with 5 selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anon/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/anon/anaconda2/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  0  0  0]\n",
      " [ 0  1  0  0  0]\n",
      " [ 0  0  2  0  0]\n",
      " [ 0  0  0 18  0]\n",
      " [ 0  0  2  0  2]]\n",
      "acc: 0.846153846154\n",
      "[[ 0  0  0  1  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  2  4  0  0]\n",
      " [ 0  0  0 17  0]\n",
      " [ 0  0  0  0  2]]\n",
      "acc: 0.884615384615\n",
      "[[ 0  0  0  0  0]\n",
      " [ 0  1  1  0  0]\n",
      " [ 0  1  2  1  0]\n",
      " [ 1  0  0 16  0]\n",
      " [ 0  0  0  0  2]]\n",
      "acc: 0.84\n",
      "[[ 0  1  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  3  0  0]\n",
      " [ 0  0  0 17  0]\n",
      " [ 0  0  0  0  2]]\n",
      "acc: 0.95652173913\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# use given features to train\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=1)\n",
    "for train_index, test_index in skf.split(hip_images, labels):\n",
    "    \n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = y_one_hot[train_index], y_one_hot[test_index]\n",
    "    \n",
    "    clf1 = MLPClassifier(max_iter=500, random_state=1)\n",
    "    clf1.fit(X_train, y_train)\n",
    "    scores = clf1.score(X_test, y_test)\n",
    "    preds = clf1.predict(X_test)\n",
    "    print(confusion_matrix(np.argmax(preds, axis=1), np.argmax(y_test, axis=1)))\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    print(\"acc: \" + str(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Neural Net with pixels as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  2  4 18  2]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]]\n",
      "acc: 0.0\n",
      "[[ 0  0  0  5  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  2  4 13  2]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]]\n",
      "acc: 0.153846153846\n",
      "[[ 1  2  3 17  2]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]]\n",
      "acc: 0.0\n",
      "[[ 0  1  3 14  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  3  2]\n",
      " [ 0  0  0  0  0]]\n",
      "acc: 0.130434782609\n"
     ]
    }
   ],
   "source": [
    "# use raw pixels to train MLP\n",
    "X = hip_images.reshape((hip_images.shape[0], -1))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=1)\n",
    "for train_index, test_index in skf.split(X, labels):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_one_hot[train_index], y_one_hot[test_index]\n",
    "    \n",
    "    clf2 = MLPClassifier(max_iter=500, random_state=1)\n",
    "    clf2.fit(X_train, y_train)\n",
    "    scores = clf2.score(X_test, y_test)\n",
    "    preds = clf2.predict(X_test)\n",
    "    print(confusion_matrix(np.argmax(preds, axis=1), np.argmax(y_test, axis=1)))\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    print(\"acc: \" + str(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN with 2 Convolution and Kernel size 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n",
      "((77, 90, 90), (23, 90, 90))\n",
      "('x_train shape:', (77, 90, 90, 1))\n",
      "(77, 'train samples')\n",
      "(23, 'test samples')\n",
      "Train on 77 samples, validate on 23 samples\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 6s - loss: 1.3954 - acc: 0.4545 - val_loss: 0.9063 - val_acc: 0.7391\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s - loss: 1.1006 - acc: 0.6883 - val_loss: 1.1226 - val_acc: 0.6957\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s - loss: 1.1140 - acc: 0.6364 - val_loss: 0.9392 - val_acc: 0.7391\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s - loss: 1.1240 - acc: 0.6883 - val_loss: 0.8805 - val_acc: 0.7391\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s - loss: 1.1051 - acc: 0.6883 - val_loss: 0.9135 - val_acc: 0.7391\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s - loss: 0.9477 - acc: 0.7013 - val_loss: 0.9063 - val_acc: 0.7391\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s - loss: 0.8568 - acc: 0.7013 - val_loss: 0.9086 - val_acc: 0.7391\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s - loss: 0.8294 - acc: 0.6883 - val_loss: 1.0845 - val_acc: 0.6522\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s - loss: 0.8929 - acc: 0.7273 - val_loss: 0.9987 - val_acc: 0.7391\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s - loss: 0.8193 - acc: 0.6883 - val_loss: 0.9455 - val_acc: 0.7391\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s - loss: 0.8681 - acc: 0.6883 - val_loss: 0.9061 - val_acc: 0.7391\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 1s - loss: 0.7517 - acc: 0.7273 - val_loss: 0.9055 - val_acc: 0.7391\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 1s - loss: 0.6792 - acc: 0.7403 - val_loss: 0.9829 - val_acc: 0.6957\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 1s - loss: 0.7257 - acc: 0.7922 - val_loss: 0.9732 - val_acc: 0.7391\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 1s - loss: 0.6369 - acc: 0.7273 - val_loss: 0.9200 - val_acc: 0.7391\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s - loss: 0.5787 - acc: 0.7662 - val_loss: 0.9362 - val_acc: 0.7391\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s - loss: 0.4882 - acc: 0.8182 - val_loss: 0.9494 - val_acc: 0.7391\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s - loss: 0.5544 - acc: 0.8442 - val_loss: 1.0334 - val_acc: 0.7391\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s - loss: 0.5319 - acc: 0.8052 - val_loss: 0.9629 - val_acc: 0.7391\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s - loss: 0.4885 - acc: 0.8312 - val_loss: 1.0114 - val_acc: 0.7391\n",
      "('Test loss:', 1.0113668441772461)\n",
      "('Test accuracy:', 0.73913043737411499)\n"
     ]
    }
   ],
   "source": [
    "# CNN in Keras\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 5\n",
    "epochs = 20\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 90, 90\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "# split = 75\n",
    "(x_train, y_train) = (hip_images[train_index, :, :], labels[train_index])\n",
    "(x_test, y_test) = (hip_images[test_index, :, :], labels[test_index])\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "y_pred = model.predict(x_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 5)\n",
      "[[ 0  0  1  0]\n",
      " [ 0  0  3  0]\n",
      " [ 0  0 17  0]\n",
      " [ 0  0  2  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 2, 2, 3, 3, 3, 3, 2, 3, 1, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3,\n",
       "       1, 1, 4, 3, 3, 0, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 1, 3,\n",
       "       3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3,\n",
       "       3, 3, 3, 3, 3, 4, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_pred.shape)\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))\n",
    "np.argmax(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN with 2 Convolution and Kernel size 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 77 samples, validate on 23 samples\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 7s - loss: 1.4409 - acc: 0.4156 - val_loss: 0.9350 - val_acc: 0.7391\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s - loss: 1.2096 - acc: 0.6364 - val_loss: 0.9783 - val_acc: 0.7391\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s - loss: 0.9951 - acc: 0.6753 - val_loss: 1.0124 - val_acc: 0.7391\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s - loss: 1.1091 - acc: 0.6883 - val_loss: 0.9022 - val_acc: 0.7391\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s - loss: 0.9938 - acc: 0.6883 - val_loss: 1.0723 - val_acc: 0.7391\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s - loss: 1.0181 - acc: 0.6623 - val_loss: 0.8870 - val_acc: 0.7391\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s - loss: 0.9158 - acc: 0.6753 - val_loss: 1.0651 - val_acc: 0.7391\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s - loss: 0.8993 - acc: 0.7143 - val_loss: 0.8714 - val_acc: 0.7391\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s - loss: 0.8503 - acc: 0.7273 - val_loss: 0.9354 - val_acc: 0.6957\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s - loss: 0.8190 - acc: 0.7143 - val_loss: 1.1251 - val_acc: 0.7391\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s - loss: 0.7516 - acc: 0.7403 - val_loss: 0.9800 - val_acc: 0.7391\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s - loss: 0.6619 - acc: 0.7143 - val_loss: 1.0116 - val_acc: 0.5217\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s - loss: 0.5944 - acc: 0.7013 - val_loss: 0.9304 - val_acc: 0.6957\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s - loss: 0.6831 - acc: 0.8312 - val_loss: 0.8720 - val_acc: 0.7391\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s - loss: 0.4042 - acc: 0.8571 - val_loss: 1.1320 - val_acc: 0.7391\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s - loss: 0.6110 - acc: 0.8312 - val_loss: 0.8893 - val_acc: 0.7391\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s - loss: 0.3597 - acc: 0.8831 - val_loss: 0.9588 - val_acc: 0.6522\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s - loss: 0.3430 - acc: 0.8701 - val_loss: 0.9190 - val_acc: 0.6957\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s - loss: 0.2486 - acc: 0.9610 - val_loss: 1.0852 - val_acc: 0.6957\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s - loss: 0.1782 - acc: 0.9351 - val_loss: 1.1328 - val_acc: 0.7391\n",
      "('Test loss:', 1.1327763795852661)\n",
      "('Test accuracy:', 0.73913043737411499)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "y_pred = model.predict(x_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN with 3 Convolution and Kernel size 3 and learning rate 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 77 samples, validate on 23 samples\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 3s - loss: 1.5229 - acc: 0.3766 - val_loss: 1.2335 - val_acc: 0.7391\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 1s - loss: 1.1419 - acc: 0.6883 - val_loss: 1.1815 - val_acc: 0.7391\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 1s - loss: 1.0746 - acc: 0.6883 - val_loss: 0.9060 - val_acc: 0.7391\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s - loss: 1.1224 - acc: 0.6883 - val_loss: 0.9318 - val_acc: 0.7391\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s - loss: 1.0948 - acc: 0.6883 - val_loss: 1.0648 - val_acc: 0.7391\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 1s - loss: 1.0461 - acc: 0.6883 - val_loss: 1.1201 - val_acc: 0.7391\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 1s - loss: 1.0448 - acc: 0.6883 - val_loss: 0.9837 - val_acc: 0.7391\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 1s - loss: 0.9886 - acc: 0.6883 - val_loss: 1.0376 - val_acc: 0.7391\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 1s - loss: 1.0522 - acc: 0.6883 - val_loss: 0.9729 - val_acc: 0.7391\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 1s - loss: 0.9951 - acc: 0.6883 - val_loss: 1.1165 - val_acc: 0.7391\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 1s - loss: 1.0289 - acc: 0.6883 - val_loss: 1.0170 - val_acc: 0.7391\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 1s - loss: 1.0290 - acc: 0.6883 - val_loss: 1.0131 - val_acc: 0.7391\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 1s - loss: 0.9462 - acc: 0.6883 - val_loss: 1.0621 - val_acc: 0.7391\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 1s - loss: 0.9865 - acc: 0.6883 - val_loss: 1.0032 - val_acc: 0.7391\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 1s - loss: 1.0461 - acc: 0.6883 - val_loss: 1.0952 - val_acc: 0.7391\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 1s - loss: 0.9543 - acc: 0.6883 - val_loss: 1.0896 - val_acc: 0.7391\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 1s - loss: 0.9956 - acc: 0.6883 - val_loss: 1.0923 - val_acc: 0.7391\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 1s - loss: 0.9935 - acc: 0.6883 - val_loss: 0.9945 - val_acc: 0.7391\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s - loss: 0.9497 - acc: 0.6883 - val_loss: 1.0441 - val_acc: 0.7391\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 1s - loss: 0.9240 - acc: 0.6883 - val_loss: 1.1678 - val_acc: 0.7391\n",
      "('Test loss:', 1.1678109169006348)\n",
      "('Test accuracy:', 0.73913043737411499)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# adding new layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# change learning rate\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(lr=0.5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "y_pred = model.predict(x_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
